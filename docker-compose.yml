
version: '3.8'
#docker-compose version 3.8
services:
  # Hadoop Cluster Services
  master1:
    image: hadoop-cluster:latest
    # build:
    #   context: .
    #   dockerfile: Dockerfile.hadoop
    hostname: master1
    container_name: master1
    environment:
      - ROLE=master
    ports:
      - "9871:9870"
      - "8081:8088"
    volumes:
      - ./code:/code:ro
      - namenode1:/hadoopdata/namenode
      - journalnode1:/hadoopdata/journalnode
    networks:
      - hadoop_net
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 5s
      timeout: 3s
      retries: 30
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G

  master2:
    image: hadoop-cluster:latest
    # build:
    #   context: .
    #   dockerfile: Dockerfile.hadoop
    hostname: master2
    container_name: master2
    environment:
      - ROLE=master
    ports:
      - "9872:9870"
      - "8082:8088"
    volumes:
      - ./code:/code:ro
      - namenode2:/hadoopdata/namenode
      - journalnode2:/hadoopdata/journalnode
    networks:
      - hadoop_net
    depends_on:
      master1:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 5s
      timeout: 3s
      retries: 30
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G

  master3:
    image: hadoop-cluster:latest
    # build:
    #   context: .
    #   dockerfile: Dockerfile.hadoop
    hostname: master3
    container_name: master3
    environment:
      - ROLE=master
    ports:
      - "9873:9870"
      - "8083:8088"
    volumes:
      - ./code:/code:ro
      - namenode3:/hadoopdata/namenode
      - journalnode3:/hadoopdata/journalnode
    networks:
      - hadoop_net
    depends_on:
      master1:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 5s
      timeout: 3s
      retries: 30
      start_period: 30s
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 2G

  worker1:
    image: hadoop-cluster:latest
    # build:
    #   context: .
    #   dockerfile: Dockerfile.hadoop
    hostname: worker1
    container_name: worker1
    environment:
      - ROLE=worker
    volumes:
      - datanode:/hadoopdata/datanode
    networks:
      - hadoop_net
    depends_on:
      master1:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G

  # Hive Services
  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hive
      - POSTGRES_DB=metastore
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - hadoop_net
    ports:
      - "25432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hive -d metastore"]
      interval: 10s
      timeout: 5s
      retries: 10

  hive-metastore:
    image: hive-cluster:latest

    # build:
    #   context: .
    #   dockerfile: Dockerfile.hive
    container_name: hive-metastore
    hostname: hive-metastore
    depends_on:
      postgres:
        condition: service_healthy
      master1:
        condition: service_healthy
    environment:
      SERVICE_NAME: metastore
    ports:
      - "19083:9083"
    networks:
      - hadoop_net
    # healthcheck:
    #   test: ["CMD", "nc", "-z", "localhost", "9083"]
    #   interval: 10s
    #   timeout: 5s
    #   retries: 10
    #   start_period: 40s

  hive-server2:
    image: hive-cluster:latest
    # build:
    #   context: .
    #   dockerfile: Dockerfile.hive
    container_name: hive-server2
    hostname: hive-server2
    depends_on:
      hive-metastore:
        condition: service_started
    volumes:
      - hive_data:/usr/local/hive/data
    ports:
      - "10000:10000"
      - "10002:10002"
    environment:
      SERVICE_NAME: hiveserver2
    networks:
      - hadoop_net


networks:
  hadoop_net:
    driver: bridge

volumes:
  namenode1:
  namenode2:
  namenode3:
  journalnode1:
  journalnode2:
  journalnode3:
  datanode:
  postgres_data:
  hive_data: