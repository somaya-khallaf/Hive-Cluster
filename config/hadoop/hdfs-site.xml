<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
    <name>dfs.nameservices</name>
    <value>hadoop-cluster</value>
    <description>
      Logical name for the HDFS namespace. Clients use this to connect to the cluster.
      Must match across all HA configurations. (Comma-separated list of nameservices.)
  </description>
  </property>

  <property>
    <name>dfs.ha.namenodes.hadoop-cluster</name>
    <value>nn1,nn2,nn3</value>
  <description>
    Unique identifiers for the NameNodes in the HA cluster (comma-separated).
    Here, three NameNodes (nn1, nn2, nn3) are configured for redundancy.
  </description>
  </property>

  <property>
    <name>dfs.namenode.rpc-address.hadoop-cluster.nn1</name>
    <value>master1:8020</value>
    <description>
      The address and the base port where the dfs namenode will listen on.
      This is the address that clients will use to connect to the NameNode.
    </description>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.hadoop-cluster.nn2</name>
    <value>master2:8020</value>
  </property>
  <property>
    <name>dfs.namenode.rpc-address.hadoop-cluster.nn3</name>
    <value>master3:8020</value>
  </property>


  <property>
    <name>dfs.namenode.http-address.hadoop-cluster.nn1</name>
    <value>master1:9870</value>
    <description>
      The address and the base port where the dfs namenode web ui will listen on.
    </description>
  </property>
  <property>
    <name>dfs.namenode.http-address.hadoop-cluster.nn2</name>
    <value>master2:9870</value>
  </property>
  <property>
    <name>dfs.namenode.http-address.hadoop-cluster.nn3</name>
    <value>master3:9870</value>
  </property>


  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://master1:8485;master2:8485;master3:8485/hadoop-cluster</value>
    <description>
      The shared edits directory for the NameNodes in the HA cluster.
      This is where the NameNodes will write their edits logs.

      A directory on shared storage between the multiple namenodes in an HA cluster. 
      This directory will be written by the active and read by the standby in order to keep the namespaces 
      synchronized. 
    </description>
  </property>

  <property>
    <name>dfs.client.failover.proxy.provider.hadoop-cluster</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    <description>
      Class responsible for client-side failover between Active/Standby NameNodes.
    </description>
  </property>
  
  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>shell(/bin/true)</value>
    <description>
      The fencing method to use for the NameNodes in the HA cluster.
      This is used to ensure that only one NameNode is active at a time.
      Fencing method to prevent split-brain scenarios. 
    </description>
  </property>

  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value>/home/hadoop/.ssh/id_rsa</value>
  </property>

  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value>/hadoopdata/journalnode</value>
  </property>

  <!-- How They Work Together
Active NameNode writes edits to the shared edits URI (qjournal://...).

JournalNodes receive edits and store them in their local edits dir (/hadoopdata/journalnode).

Standby NameNode reads edits from the same shared URI to stay in sync. -->

  <property>
    <name>dfs.ha.nn.not-become-active-in-safemode</name>
    <value>true</value>
    <description>
      Prevents a NameNode from becoming Active if it starts in Safemode.
      Avoids data inconsistency during failover.
      This will prevent safe mode namenodes to become active 
      or observer while other standby namenodes might be ready to serve requests when it is set to true.
      If true, prevents a NameNode from becoming Active while in Safemode.
      This ensures metadata is fully loaded before accepting write operations.
    </description>
  </property>

 <property>
    <name>dfs.namenode.name.dir</name>
    <value>/hadoopdata/namenode</value>
    <description>
      Directory for NameNode metadata (fsimage, edits).
 	    Determines where on the local filesystem the DFS name node should store the name table(fsimage). 
      If this is a comma-delimited list of directories then 
      the name table is replicated in all of the directories, for redundancy.
    </description>
    </property>

  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
    <description>
      Enables automatic failover using ZooKeeper (requires ZKFC daemons).
      Manual failover if set to false.
    </description>
  </property>

  <property>
    <name>dfs.datanode.data.dir</name>
    <value>/hadoopdata/datanode</value>
    <description>
      Directory for DataNode block storage. 
      Determines where on the local filesystem an DFS data node should store its blocks.
    </description>
  </property>
</configuration>
